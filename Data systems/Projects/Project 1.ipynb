{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a09a2a",
   "metadata": {},
   "source": [
    "# Data Systems: Project 1a\n",
    "## Author: Joseph Bannon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4578d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599f97a",
   "metadata": {},
   "source": [
    "The main function combines the logical steps in each other function, see other functions for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "262f64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Welcome to the data systems ETL progam \\n Note: the paratheses contain the strings the user should input\",flush=True)\n",
    "    pd_df = getData()\n",
    "    if pd_df is None:\n",
    "        print(\"\\nexiting\")\n",
    "        return\n",
    "    \n",
    "    pd_df = modifyData(pd_df)\n",
    "    if pd_df is None:\n",
    "        print(\"\\nexiting\")\n",
    "        return\n",
    "    \n",
    "    summary(pd_df)\n",
    "    \n",
    "    writeData(pd_df)    \n",
    "    print(\"\\nexiting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6b7b1",
   "metadata": {},
   "source": [
    "### 1) Get Data\n",
    "This function is responsible for getting data from a source specified by the user. It takes CSV, JSON, SQL database, API from URL. There are several functions that deal with each data type and specific ways to connect to each data source. They all take the data and convert the data into a pandas dataframe for later manipulation by the user. The data must be in the current working directory to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "026d2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"GET DATA\")\n",
    "    fileType = input(\"What is the file type of the target (options: csv, json, sqldb, api or exit): \").strip().lower()\n",
    "    \n",
    "    pd_df = None\n",
    "    \n",
    "    if fileType == \"csv\":\n",
    "        fileLocation = input(\"What is the location of the target: \").strip().lower()\n",
    "        pd_df = getCSV(fileLocation)\n",
    "        \n",
    "    elif fileType == \"json\":\n",
    "        fileLocation = input(\"What is the location of the target: \").strip().lower()\n",
    "        pd_df = getJSON(fileLocation)\n",
    "        \n",
    "    elif fileType == \"sqldb\":\n",
    "        str_cred = input(\"Connection String (str) or Credentials (cred)? \").strip().lower()\n",
    "\n",
    "        if str_cred == \"str\":\n",
    "            conn_str = input(\"What is the connection string of the target datbase: \")\n",
    "            table = input(\"Table Name: \")\n",
    "            pd_df = get_SQL_str(conn_str, table)\n",
    "\n",
    "        elif str_cred == \"cred\":\n",
    "            user_id = input(\"User Id: \")\n",
    "            pwd = input(\"Password: \")\n",
    "            host_name = input(\"Host Name: \")\n",
    "            db_name = input(\"Database Name: \")\n",
    "            table = input(\"Table Name: \")\n",
    "            pd_df = get_SQL_cred(user_id, pwd, host_name, db_name, table)\n",
    "            \n",
    "        elif fileType == \"exit\":\n",
    "            getData()\n",
    "        \n",
    "        else:\n",
    "            print(\"Not a listed choice(options: str, cred), try again\")\n",
    "            getData()        \n",
    "        \n",
    "    elif fileType == \"api\": #add in http get requests\n",
    "        fileLocation = input(\"What is the url of the target api: \").strip().lower()\n",
    "        #fileLocation = \"http://universities.hipolabs.com/search?name=middle\"\n",
    "        get_api_response(fileLocation)\n",
    "            \n",
    "            \n",
    "    elif fileType == \"exit\":\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        print(\"Not a listed choice(options: csv, json, sqldb, api or exit), try again\")\n",
    "        getData()\n",
    "    print(\"Data collection sucessful\")\n",
    "    return pd_df\n",
    "    \n",
    "#https://universities.hipolabs.com/search?name=middle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4a286",
   "metadata": {},
   "source": [
    "CSV file input to pandas df (url or local file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8cb9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSV(fileLocation):\n",
    "    try:\n",
    "        csv_df = pd.read_csv(fileLocation)\n",
    "        return csv_df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found, try again\")\n",
    "        getData()\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        getData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c780c7",
   "metadata": {},
   "source": [
    "JSON file input to pandas df (url or local file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b75b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJSON(fileLocation):\n",
    "    try:\n",
    "        json_df = pd.read_json(fileLocation)\n",
    "        #display(json_df.head())\n",
    "        return json_df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found, try again\")\n",
    "        getData()\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f036c",
   "metadata": {},
   "source": [
    "Input is the database credentials and table to load, turn the table into a pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f202594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_name = \"localhost\"\n",
    "# host_ip = \"127.0.0.1\"\n",
    "# port = \"3306\"\n",
    "\n",
    "# user_id = \"root\"\n",
    "# pwd = \"Antvenom21!\"\n",
    "# src_dbname = \"northwind\"\n",
    "# dst_dbname = \"northwind_dw2\"\n",
    "\n",
    "def get_SQL_cred(user_id, pwd, host_name, db_name, table):\n",
    "    try:\n",
    "        conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "        sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "        connection = sqlEngine.connect()\n",
    "        sql_query = f\"SELECT * FROM {db_name}.{table}\"\n",
    "        dframe = pd.read_sql(sql_query, connection);\n",
    "        connection.close()\n",
    "        return dframe\n",
    "    except:\n",
    "        print(\"Connection error, try again\")\n",
    "        getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e11c9",
   "metadata": {},
   "source": [
    "Input is the connection string and table to load, turns the table into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0f95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SQL_str(conn_str, table):\n",
    "    try:\n",
    "        #conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "        sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "        connection = sqlEngine.connect()\n",
    "        db_name = conn_str[conn_str.rfind(\"/\")+1:]\n",
    "        sql_query = f\"SELECT * FROM {db_name}.{table}\"\n",
    "        dframe = pd.read_sql(sql_query, connection);\n",
    "        connection.close()\n",
    "        return dframe\n",
    "    except:\n",
    "        print(\"Connection error, try again\")\n",
    "        getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da24d4",
   "metadata": {},
   "source": [
    "Input is the http location of an api, turns the reponse json into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9a68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_response(fileLocation):\n",
    "    try:\n",
    "        response = requests.get(fileLocation)\n",
    "        if (response.status_code != 200):\n",
    "            print(\"API request unsuccessful, try again\")\n",
    "            getData()     \n",
    "        json_file = json.loads(response.text)\n",
    "        pd_df = pd.DataFrame.from_dict(json_file)\n",
    "        return pd_df\n",
    "    except:\n",
    "        print(\"Json conversion unsuccesful, try again\")\n",
    "        getData()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d891428",
   "metadata": {},
   "source": [
    "### 2) Modify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a8cfa",
   "metadata": {},
   "source": [
    "This function is takes the input of a dataframe (pd_df) from the getData() function. The function is able to remove a column by name ('remove_column'), adding a column with a default value and type specified by the user ('add_column'), or nothing ('none'). When adding a column, the user can add a primary key by typing '\\_primaryKey' with unique integer key value. Also, the user can add NULL values by entering \"\\_NA\". Another feature is adding a column via expression by typing 'add_column_exp', which uses compile and exec commands in python. A user can enter a expression involving other columns, that is evaluted into code, that the program will use to create a new column based off data in the old column. For example, \"pd_df\\['longitude'\\]\\*2\" results in each row in the new column being the corresponding double of the row in the column \"longitude\". Typing head class the head function on the dataframe. Typing 'none' exits the function returning the modified dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b896196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifyData(pd_df):\n",
    "    print(\"\")\n",
    "    print(\"MODIFY DATA\")\n",
    "    print(\"Note: add a column as an expression of other columns by typing 'add_column_exp'\")\n",
    "    columnType = input(\"How would you like to change the dataframe (options: remove_column, add_column, head, add_column_exp, none): \").strip().lower()\n",
    "    # add primary key?\n",
    "    \n",
    "    if columnType == \"remove_column\":\n",
    "        print(\"Here is a list of columns: \")\n",
    "        print(*(pd_df.columns), sep = \", \")\n",
    "        try:\n",
    "            rm_col = [item for item in input(\"Enter the list of columns to remove: \").split(\", \")]\n",
    "            pd_df = pd_df.drop(rm_col, axis=1)\n",
    "            print(\"removing succesful\")\n",
    "            modifyData(pd_df)\n",
    "        except:\n",
    "            print(\"removing unsuccesful\")\n",
    "        \n",
    "    elif columnType == \"add_column\":\n",
    "        colName = input(\"Column name: \")\n",
    "        defaultValue = input(\"What default value should be used (type '_primaryKey' for primary key, '_NA' for N/A): \")\n",
    "        try:\n",
    "            if defaultValue == \"_primaryKey\":\n",
    "                pd_df.insert(0,colName,range(pd_df.shape[0]))\n",
    "                print(\"Sucessfully added\")\n",
    "                modifyData(pd_df)\n",
    "\n",
    "            elif defaultValue == \"_NA\":\n",
    "                pd_df.insert(0,colName,np.nan)\n",
    "                print(\"Sucessfully added\")\n",
    "                modifyData(pd_df)\n",
    "\n",
    "            else:\n",
    "                typeD = input(\"What data type should it be (int, string, bool, double): \")\n",
    "                index = int(input(\"What position should the column be: \"))\n",
    "                if typeD == \"int\":\n",
    "                    defaultValue = int(defaultValue)\n",
    "                elif typeD == \"bool\":\n",
    "                    defaultValue = bool(defaultValue)\n",
    "                elif typeD == \"double\":\n",
    "                    defaultValue = float(defaultValue)\n",
    "                elif typeD == \"string\":\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"invalid choice\")\n",
    "                    modifyData(pd_df)\n",
    "                pd_df.insert(index,colName,defaultValue)\n",
    "                print(\"Sucessfully added\")\n",
    "                modifyData(pd_df)\n",
    "        except:\n",
    "            print(\"adding column unsuccessful\")\n",
    "            modifyData(pd_df)\n",
    "            \n",
    "    elif columnType == \"add_column_exp\":\n",
    "        try:\n",
    "            colName = input(\"Column name to add: \")\n",
    "            index = int(input(\"What position should the column be: \"))\n",
    "            print(\"Access a column by typing: pd_df['COLUMNNAME']\")\n",
    "            print(\"Replace COLUMNNAME with the name, must include '' still, must use 'pd_df' to access the dataframe\")\n",
    "            print(\"ex: pd_df['longitude']*2,\")\n",
    "            print(\"results in each row in the new column being the double of the row in the column 'longitude'\")\n",
    "            exp = input(\"What expression are you using: \")\n",
    "            code = compile(exp, \"<string>\", \"eval\")\n",
    "            column = eval(code)\n",
    "            pd_df.insert(index,colName,column)\n",
    "            print(\"Sucessfully added\")\n",
    "            modifyData(pd_df)\n",
    "        except:\n",
    "            print(\"invalid expression, try again\")\n",
    "            modifyData(pd_df)\n",
    "    \n",
    "    elif columnType == \"none\":\n",
    "        return pd_df\n",
    "    \n",
    "    elif columnType == \"head\":\n",
    "        display(pd_df.head())\n",
    "        modifyData(pd_df)\n",
    "    else:\n",
    "        print(\"Not a listed choice (options: remove_column, add_column, none), try again\")\n",
    "        modifyData(pd_df)\n",
    "        \n",
    "    modifyData(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6915a8",
   "metadata": {},
   "source": [
    "### 3) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cdd37",
   "metadata": {},
   "source": [
    "The summary function gives a summary of several attributes of the dataframe. These attributes include the number of rows, number of columns, columns with N/A values and a list of all columns and their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241ccd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(pd_df):\n",
    "    print(\" \")\n",
    "    print('Summary of data collected')\n",
    "    print('Number of rows are: ', pd_df.shape[0])\n",
    "    print('Number of columns are: ', pd_df.shape[1])\n",
    "    print('Columns containing NA:')\n",
    "    print(*(pd_df.columns[pd_df.isna().any()].tolist()), sep = \", \" )\n",
    "    print('Columns and data types:')\n",
    "    print(pd_df.dtypes)\n",
    "    display(pd_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6005ad8",
   "metadata": {},
   "source": [
    "### 4) writeData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398ca3b",
   "metadata": {},
   "source": [
    "The writeData function takes input from modifyData. The function allows the user to write the write to csv, json, sqldb. For csv and json, the user can specify a name for the created file. The program creates the file at current working directory of this jupyter notebook. For adding a table to a SQL database (sqldb), the user can connect to the database using a connection string (str) or user credentials (cred). The user can also add a table name to be created in the database (table is replaced if the name already exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea3e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeData(pd_df):\n",
    "    fileType = input(\"What is the file type of what you want to write (options: csv, json, sqldb): \").strip().lower()\n",
    "    fileName = input(\"What is the name of the file: \").strip().lower()\n",
    "    if fileType == \"csv\":\n",
    "        writeCSV(pd_df, fileName)\n",
    "        \n",
    "    elif fileType == \"json\":\n",
    "        writeJSON(pd_df, fileName)\n",
    "        \n",
    "    elif fileType == \"sqldb\":\n",
    "        str_cred = input(\"Connection String (str) or Credentials (cred)? \").strip().lower()\n",
    "\n",
    "        if str_cred == \"str\":\n",
    "            conn_str = input(\"What is the connection string of the target datbase: \")\n",
    "            table = input(\"Table Name: \")\n",
    "            write_SQL_str(pd_df, conn_str, table)\n",
    "\n",
    "        elif str_cred == \"cred\":\n",
    "            user_id = input(\"User Id: \")\n",
    "            pwd = input(\"Password: \")\n",
    "            host_name = input(\"Host Name: \")\n",
    "            db_name = input(\"Database Name: \")\n",
    "            table = input(\"Table Name to be created: \")\n",
    "            write_SQL_cred(pd_df,  user_id, pwd, host_name, db_name, table)\n",
    "            \n",
    "        elif fileType == \"exit\":\n",
    "            writeData(pd_df)\n",
    "        \n",
    "        else:\n",
    "            print(\"Not a listed choice (options: str, cred), try again\")\n",
    "            writeData(pd_df)        \n",
    "    \n",
    "    else:\n",
    "        print(\"Not a listed choice (options: csv, json, sqldb), try again\")\n",
    "        writeData(pd_df)\n",
    "    print(\"Data Writing sucessful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038be4f",
   "metadata": {},
   "source": [
    "CSV file output from pandas df (creates file at current working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c82fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(pd_df, fileName):\n",
    "    try:\n",
    "        pd_df.to_csv(fileName, index=True, sep=',')\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        writeData(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ceafd",
   "metadata": {},
   "source": [
    "JSON file output from pandas df (creates file at current working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714a1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJSON(pd_df, fileName):\n",
    "    try:\n",
    "        pd_df.to_json(fileName)\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        writeData(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108e449",
   "metadata": {},
   "source": [
    "Input is the database credentials and table to create in the sql db, creates a table in the database specified, replacing the table if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c870ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_SQL_str(pd_df, conn_str, table):\n",
    "    #conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    try:\n",
    "        sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "        connection = sqlEngine.connect()\n",
    "\n",
    "        pd_df.to_sql(table, con=connection, index=False, if_exists='replace')\n",
    "        str_cred = input(\"Add key? (y/n)\").strip().lower()\n",
    "        if str_cred == \"y\":\n",
    "            print(\"List of columns: \")\n",
    "            print(*(pd_df.columns.tolist()), sep = \", \" )\n",
    "            pk_column = input(\"What is the column name?\").strip().lower()\n",
    "            sqlEngine.execute(f\"ALTER TABLE {table} ADD PRIMARY KEY ({pk_column});\")\n",
    "\n",
    "        connection.close()\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        writeData(pd_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a33748",
   "metadata": {},
   "source": [
    "Input is the connection string and table to create in the sql db, creates a table in the database specified, replacing the table if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35ee074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_SQL_cred(pd_df, fileName,  user_id, pwd, host_name, db_name, table):\n",
    "    try:\n",
    "        conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "        sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "        connection = sqlEngine.connect()\n",
    "\n",
    "        pd_df.to_sql(table, con=connection, index=False, if_exists='replace')\n",
    "        str_cred = input(\"Add key? (y/n)\").strip().lower()\n",
    "        if str_cred == \"y\":\n",
    "            print(\"List of columns: \")\n",
    "            print(*(pd_df.columns.tolist()), sep = \", \" )\n",
    "            pk_column = input(\"What is the column name: \").strip().lower()\n",
    "            sqlEngine.execute(f\"ALTER TABLE {table} ADD PRIMARY KEY ({pk_column});\")\n",
    "\n",
    "        connection.close()\n",
    "    except:\n",
    "        print(\"Error, try again\")\n",
    "        writeData(pd_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ebf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the data systems ETL progam \n",
      " Note: the paratheses contain the strings the user should input\n",
      "\n",
      "GET DATA\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2277281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NEAR BAY\n",
       "1        NEAR BAY\n",
       "2        NEAR BAY\n",
       "3        NEAR BAY\n",
       "4        NEAR BAY\n",
       "           ...   \n",
       "20635      INLAND\n",
       "20636      INLAND\n",
       "20637      INLAND\n",
       "20638      INLAND\n",
       "20639      INLAND\n",
       "Name: ocean_proximity, Length: 20640, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = pd.read_csv(\"housing.csv\")\n",
    "pd_df['ocean_proximity']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
